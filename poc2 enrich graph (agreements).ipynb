{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1924e01-f8a6-40a6-ab9f-53b6b7bc1ba0",
   "metadata": {},
   "source": [
    "# Application of LLM-Augmented Knowledge Graphs for Wirearchy Management\n",
    "\n",
    "### Universitat Oberta de Catalunya\n",
    "### Data Science Master's Degree - Data Analysis and Big Data.<br>Final project\n",
    "\n",
    "- Author: Xavier Ventura de los Ojos\n",
    "- Project Supervisor: Francesc Julbe López\n",
    "- Coordinating Professor: Albert Solé Ribalta\n",
    "- Date of submission: 06/2024\n",
    "\n",
    "## POC 2: How to enrich a KG extracting content from semistructured documents\n",
    "\n",
    "### Overview\n",
    "\n",
    "Once the initial graph is modeled and the nodes and relationships created from strucutured files, we propose enriching it by extracting additional information from semistructured documents.\n",
    "This task is known as Named Entity Recognition or NER.\n",
    "\n",
    "In this POC 2 we showcase how Large Language Models (LLM) can be used to perform this NER task.<br>\n",
    "The process consists on sending the extraction instructions (prompt) including the document content (text only) and the schema of interest.\n",
    "Following the template instruction, the model should result the content in the form of a python dict.\n",
    "The structured output from the LLM is enriched and then saved in a JSON file.<br>\n",
    "This file is used for model performance analysis and for the actual enrichment of the graph.\n",
    "\n",
    "It is NOT in the scope of the POC 2:\n",
    "- Process images or sounds as input for the model.\n",
    "- Implement a Langchain (generic) Agent that would categorize the document and proxy it to the corresponding extractor chain / schema. Instead we will focus on a specific use case.\n",
    "\n",
    "### Use case: Agreements.\n",
    "\n",
    "To illustrate the end to end process from entity identification to graph enrichment, we focus on a specific scenario which is relevant to the graph dataset.\n",
    "\n",
    "The documents used for this POC 2 are the agreements published in PDF format in the open [Registre de Convenis of the Generalitat de Catalunya](https://registredeconvenis.gencat.cat) \n",
    "\n",
    "The information about the agreements is already part of the graph in the form of nodes labeled \"Agreement\".\n",
    "But these nodes are isolated from the other entities.\n",
    "\n",
    "The goal of this POC 2 is to connect the isolated \"Agreement\" nodes to the rest of the Graph.\n",
    "More especificaly the connection will happen by:\n",
    "\n",
    "* Creating necessary new \"Person\" nodes.\n",
    "* Creating the SIGNED relationship between the \"Person\" nodes and the agreement.\n",
    "* Adding the role, organization and document properties to the SIGNED relationship.\n",
    "* Creating new Groups if the organization does not exist already.\n",
    "* Creating the REPRESENT relationship between the Person and the Organization or Group.\n",
    "* Creating the SIGNED relationship between the Organization or Group and the Agreement.\n",
    "\n",
    "\n",
    "Luckily the list of URL is already available in the \"Agreement\" nodes of the Graph (see: POC 1).\n",
    "\n",
    "Sample document URL:\n",
    "\n",
    "https://registredeconvenis.gencat.cat/drep_rccc/public/Convenis.do?accion=DownloadDocumentsConveni&numFila=0&numConveni=2022/P/0126\n",
    "\n",
    "\n",
    "> For the sake of concisseness and cost and time savings, we don't attempt to load all the available documents but only those related to the code 2022/9/0304. If needeed, it is straightforward to extend the scope by just calling the *query_agreement* function with other agreement codes or just change the cypher query as per requirements.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b7639e-8c0b-4d73-a237-e08e47ba1004",
   "metadata": {},
   "source": [
    "## Components to parse documents and enrich the graph\n",
    "\n",
    "|Component| Type | Description|\n",
    "|---|---|--|\n",
    "|<br><strong>Components for document parsing / NER task</strong><br>|\n",
    "|parse|function|Parse a document or URL content and returns a list of documents.|\n",
    "|Document schema (pydantic):||\n",
    "| - Signee|class|Describe what is a document signee.|\n",
    "| - Agreement|class|Describe what information to extract from an agreement.|\n",
    "|PROMPT|ChatPromptTemplate|Template with extraction instructions.|\n",
    "|LLMS|dict|Langchain Chats in scope of the POC.|\n",
    "|extract|function|Returns the structured content from a text document given a schema and saves it in JSON format.|\n",
    "|extract_documents|procedure|Extracts the structured content from a list of documents and stores it in JSON files.|\n",
    "|<br>**Components for graph enrichment**<br>|\n",
    "|update_graph_agreement|procedure|Updates the Graph with the information extracted from one agreement.|\n",
    "|process_json_files|procedure|Load the json files located in the specified folder into the Graph.|\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633a8e6b-949c-4e86-a3ad-aea0e4973eab",
   "metadata": {},
   "source": [
    "### Initial setup \n",
    "\n",
    "The following API keys and Neo4j pwd are expected to be available as environment variables:\n",
    "\n",
    "- OPENAI_API_KEY: OpenAI API KEY.\n",
    "- ANTHROPIC_API_KEY: Anthropic API KEY.\n",
    "- LANGCHAIN_API_KEY: (Recommended).\n",
    "- NEO4J_PWD: Password of the Neo4j user.\n",
    "\n",
    "\n",
    "Execute the following %pip commands to install required packages if needed."
   ]
  },
  {
   "cell_type": "raw",
   "id": "448e940d-3c59-45ca-9962-9c09d33ba0b6",
   "metadata": {},
   "source": [
    "!pip install python-magic\n",
    "!pip install lxml\n",
    "!pip install pdfminer-six"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0134976-dfd1-4c33-8fcf-d4f445f8f725",
   "metadata": {},
   "source": [
    "> There is a challenge with pulling documents from \"portaldogc.gencat.cat\" because of old Cipher: AES256-SHA.<br>\n",
    "Use the following cell to downgrade the urllib3 to version 1.26.15 if you want to pull documents from \"portaldogc.gencat.cat\".\n",
    ">\n",
    "> More info: https://github.com/urllib3/urllib3/issues/3100\n",
    "> \n",
    "> % openssl s_client -connect portaldogc.gencat.cat:443 \n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a5a9250d-d1a4-4e96-bfc9-4d0cc385a4c6",
   "metadata": {},
   "source": [
    "%pip show urllib3\n",
    "%pip install --upgrade --force-reinstall urllib3==1.26.15\n",
    "%pip show urllib3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4612595-31e7-40db-bffc-73e90b491394",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import required modules\n",
    "\n",
    "import requests\n",
    "import os, glob\n",
    "\n",
    "import magic\n",
    "from langchain.document_loaders.parsers import BS4HTMLParser, PDFMinerParser\n",
    "from langchain.document_loaders.parsers.generic import MimeTypeBasedParser\n",
    "from langchain.document_loaders.parsers.txt import TextParser\n",
    "from langchain_community.document_loaders import Blob\n",
    "from langchain_community.callbacks.manager import get_openai_callback\n",
    "\n",
    "from typing import List, Optional\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "\n",
    "import json\n",
    "\n",
    "from neo4j import GraphDatabase\n",
    "\n",
    "import datetime, time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2c2b0e-8da1-483f-b352-308859d0b07e",
   "metadata": {},
   "source": [
    "### Components for document parsing / NER task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef7bce0c-b788-43eb-8c4e-b57b0db3d40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constants\n",
    "\n",
    "NEO4J_URI = \"bolt://localhost:7687\"\n",
    "NEO4J_AUTH = (\"neo4j\",  os.environ['NEO4J_PWD'])\n",
    "\n",
    "# Folders\n",
    "EXTRACTS_FOLDER = \"poc2_extracts\"\n",
    "\n",
    "# Configure the parsers that you want to use per mime-type!\n",
    "HANDLERS = {\n",
    "    \"application/pdf\": PDFMinerParser(),\n",
    "    \"text/plain\": TextParser(),\n",
    "    \"text/html\": BS4HTMLParser(),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ffe3733-9783-41c1-b8f3-09f2a987f5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(url=None,file_name=None, **kwargs):\n",
    "    \"\"\"Parses a URL or file and returns  \n",
    "\n",
    "    Args:\n",
    "        url: Url pointing to the web or resource to parse\n",
    "        file_name: Name of the file to be parsed.\n",
    "\n",
    "    Returns:\n",
    "        A list of documents\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    # Open URL or document\n",
    "    \n",
    "    if url:\n",
    "        response = requests.get(url)\n",
    "        data = response.content\n",
    "    if file_name:\n",
    "        data = open(file_name,'rb').read()\n",
    "\n",
    "    # Parse document based on the file type\n",
    "    \n",
    "    # Configure the parsers that you want to use per mime-type!\n",
    "    \"\"\"\n",
    "    HANDLERS = {\n",
    "        \"application/pdf\": PDFMinerParser(),\n",
    "        \"text/plain\": TextParser(),\n",
    "        \"text/html\": BS4HTMLParser(),\n",
    "    }\n",
    "\n",
    "    # Instantiate a mimetype based parser with the given parsers\n",
    "    MIMETYPE_BASED_PARSER = MimeTypeBasedParser(\n",
    "        handlers=HANDLERS,\n",
    "        fallback_parser=None,\n",
    "    )\n",
    "    \"\"\"\n",
    "    mime = magic.Magic(mime=True)\n",
    "    mime_type = mime.from_buffer(data)\n",
    "\n",
    "    print(\"mime_type: \",mime_type, \" size: \", len(data))\n",
    "    # A blob represents binary data by either reference (path on file system)\n",
    "    # or value (bytes in memory).\n",
    "    \n",
    "    blob = Blob.from_data(data=data, mime_type=mime_type,)\n",
    "\n",
    "    parser = HANDLERS[mime_type]\n",
    "    documents = parser.parse(blob=blob)\n",
    "    \n",
    "    return documents\n",
    "        "
   ]
  },
  {
   "cell_type": "raw",
   "id": "7d52c970-ba77-417f-8a30-574cfa96474f",
   "metadata": {},
   "source": [
    "url=\"https://registredeconvenis.gencat.cat/drep_rccc/public/Convenis.do?accion=DownloadDocumentsConveni&numFila=0&numConveni=2022/P/0127\"\n",
    "print(url)\n",
    "doc = parse(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26c8219-3e85-443e-9308-92e0a8c41891",
   "metadata": {},
   "source": [
    "### Define the document Schema\n",
    "\n",
    "We use pydantyc to define the structure of the expected output.\n",
    "\n",
    "In this POC we will parse the agreements to learn who signed them from the document contents.\n",
    "\n",
    "For this we define the classes:\n",
    "\n",
    "- Signee: To capture the information about the person who signs the agreement on behalf of an organization.\n",
    "- Agreement: To capture the agreement title, date and the list of Signees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "321202ba-3176-4ed0-9c34-e64223a1ffe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Signee(BaseModel):\n",
    "    \"\"\"Information about the person who signs the agreement on behalf of an organization.\"\"\"\n",
    "\n",
    "    # ^ Doc-string for the entity Signee.\n",
    "    # This doc-string is sent to the LLM as the description of the schema Signee,\n",
    "    # and it can help to improve extraction results.\n",
    "\n",
    "    # Note that:\n",
    "    # 1. Each field is an `optional` -- this allows the model to decline to extract it!\n",
    "    # 2. Each field has a `description` -- this description is used by the LLM.\n",
    "    # Having a good description can help improve extraction results.\n",
    "    name: Optional[str] = Field(default=None, description=\"The name of the person\")\n",
    "    organization: Optional[str] = Field(default=None, description=\"The name of the organization that the person represents if known\")\n",
    "    role: Optional[str] = Field(default=None, description=\"The role of the person within the organization if known\")\n",
    "    document: Optional[str] = Field(default=None, description=\"The document proving the person's role within the organization if known\")\n",
    "    \n",
    "\n",
    "class Agreement(BaseModel):\n",
    "    \"\"\"Extracted data about an agreement and the people signing it.\"\"\"\n",
    "\n",
    "    # Creates a model so that we can extract multiple entities.\n",
    "    # (description=\"List of Personnel Actions\")\n",
    "    title: Optional[str] = Field(default=None, description=\"Title of the agreement\")\n",
    "    # summary: Optional[str] = Field(default=None, description=\"The document summary\")\n",
    "    date: Optional[str] = Field(default=None, description=\"The date of the agreement in YYYY-MM-DD format\")\n",
    "    # CVE: Optional[str] = Field(default=None, description=\"Document code with the prefix 'CVE-DOGC' if known\")\n",
    "    people: List[Signee] = Field(description=\"List of the agreement participants if known\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20125e0-3650-452f-9d40-77cd81ee8b92",
   "metadata": {},
   "source": [
    "### Extraction Prompt\n",
    "\n",
    "We define a custom prompt to provide the extraction instructions and any additional context.\n",
    " 1) You can add examples into the prompt template to improve extraction quality\n",
    " 2) Introduce additional parameters to take context into account (e.g., include metadata\n",
    "    about the document from which the text was extracted.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a707ac7-fde1-45cd-a8dd-fc7edf1f4398",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are an expert extraction algorithm. \"\n",
    "            \"The text is about an agreement between diferent parties. \"\n",
    "            \"Only extract information from the text. \"\n",
    "            \"Do not translate the content, produce any summary using the language of the document. \"\n",
    "            \"If you do not know the value of an attribute asked to extract, \"\n",
    "            \"return null for the attribute's value.\",\n",
    "        ),\n",
    "        # Please see the how-to about improving performance with\n",
    "        # reference examples.\n",
    "        # MessagesPlaceholder('examples'),\n",
    "        (\"human\", \"{text}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4a5a6e-71db-404c-b6ca-e6823099fb1e",
   "metadata": {},
   "source": [
    "### Create the Chats to interact with the LLM Models (OpenAI and Anthropic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3da830ba-dfbc-43c9-8326-369f41edf0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the chats to interact with the LLMs.\n",
    "LLMS={}\n",
    "\n",
    "# OpenAI models\n",
    "LLMS[\"gpt-3.5-turbo\"] = ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo\")\n",
    "LLMS[\"gpt-4-turbo\"]   = ChatOpenAI(temperature=0, model=\"gpt-4-turbo\")\n",
    "LLMS[\"gpt-4o\"]   = ChatOpenAI(temperature=0, model=\"gpt-4o\") # gpt-4o released 2024-05-13\n",
    "\n",
    "# Anthropic models: https://docs.anthropic.com/en/docs/models-overview#model-comparison\n",
    "LLMS[\"claude-3-haiku\"] = ChatAnthropic(temperature=0, model_name=\"claude-3-haiku-20240307\")\n",
    "LLMS[\"claude-3-opus\"]  = ChatAnthropic(temperature=0, model_name=\"claude-3-opus-20240229\")\n",
    "\n",
    "REQUESTS_PER_MINUTE = {\"claude-3-haiku\": 5, \"claude-3-opus\": 5}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27739a0-2602-49fa-84be-8f61a0b8f566",
   "metadata": {},
   "source": [
    "## Extract document's content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8c4584c-ab0a-4f1f-8091-287e54cc102f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: LANGCHAIN_TRACING_V2=true\n",
      "env: LANGCHAIN_PROJECT=POC_2\n"
     ]
    }
   ],
   "source": [
    "%env LANGCHAIN_TRACING_V2 = true\n",
    "%env LANGCHAIN_PROJECT = POC_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6250266a-309a-403b-af53-326bcd639bc2",
   "metadata": {},
   "source": [
    "Extract information from document and save it in JSON format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94097ca1-357f-4d2c-9816-8cec47049a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract the schema entities from the document\n",
    "\n",
    "def now():\n",
    "    return datetime.datetime.now(datetime.UTC).strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "\n",
    "def extract(document,model_name,schema=Agreement, verbose=False):\n",
    "    \"\"\"Returns the structured content from a text document given a schema and saves it in JSON format.\n",
    "\n",
    "    The process consists on the following steps:\n",
    "        - parse: extract the text from the document or url.\n",
    "        - extract: perform the NER task invoking the LLM.\n",
    "        - store: optionally store the extracted information in a JSON file.\n",
    "\n",
    "    Args:\n",
    "        document: dict with the following keys:\n",
    "            \"code\": Agreement code.\n",
    "            \"url\": Url of the agreement document.\n",
    "            \"json_file\": Filename where the structured data with additional metadata will be stored\n",
    "        model_name: langchain chat (LLM) perfoming the NER\n",
    "        schema: definition of the structured data to extract (defaults to Agreement)\n",
    "        verbose: flag to indicate whether to output details of the process\n",
    "\n",
    "    Returns:\n",
    "        A tuple with:\n",
    "            - entities extracted from the document.\n",
    "            - dict with the entities plus additional metadata.\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    doc = parse(**document)\n",
    "    \n",
    "    print(document)\n",
    "    if verbose:\n",
    "        print(len(doc), doc[0].metadata, len(doc[0].page_content))\n",
    "        print(doc[0].page_content[:200]) \n",
    "\n",
    "    # Call LLM to extract entities from the document\n",
    "    if verbose: print(\"\\nCalling LLM:\\n\")\n",
    "\n",
    "    runnable = PROMPT | LLMS[model_name].with_structured_output(schema=schema)\n",
    "   \n",
    "    text = doc[0].page_content\n",
    "\n",
    "    # To save token usage and parse time we only send the first 5000 chars of the document \n",
    "    # where the signature information is usually found\n",
    "    text = text[:5000]\n",
    "\n",
    "    timestamp = now()\n",
    "    start_time = time.time()\n",
    "    with get_openai_callback() as cb:\n",
    "        entities = runnable.invoke({\"text\": text},\n",
    "                                   {\"tags\": [\"POC2\", model_name],\n",
    "                                    \"metadata\": {\"code\":document[\"code\"], \"llm\": model_name, \n",
    "                                                 \"size\": len(text), \"output\": document[\"json_file\"]}})\n",
    "    extract_time = time.time() - start_time\n",
    "    \n",
    "    # Add document medatata to the LLM results\n",
    "    data = entities.dict()\n",
    "    data[\"code\"] = document[\"code\"]\n",
    "    data[\"url\"] = document[\"url\"]\n",
    "    metadata = {\"model_name\": model_name, \"start_time\": timestamp, \"total_time\": extract_time}\n",
    "    # Add token and cost information when available\n",
    "    if cb.total_tokens > 0:\n",
    "        metadata.update({\"prompt_tokens\": cb.prompt_tokens,\n",
    "                        \"completion_tokens\": cb.completion_tokens,\n",
    "                        \"total_tokens\": cb.total_tokens,\n",
    "                        \"total_cost\": cb.total_cost})\n",
    "    data[\"metadata\"] = metadata\n",
    "    \n",
    "    # Save the results from the LLM into a JSON file if required\n",
    "    if document[\"json_file\"]:\n",
    "        with open(document[\"json_file\"],'w') as fp:\n",
    "            json.dump(data, fp, ensure_ascii=False, indent=4)\n",
    "            \n",
    "    if verbose: print(data); print()\n",
    "    \n",
    "    return (entities, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce2a41bf-fb71-4988-9dcb-c8c28a4ce6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the estructured content from the list of docs and stores it in a JSON file.\n",
    "\n",
    "def extract_documents(doclist, folder, model_name, schema=Agreement, verbose=False):\n",
    "    \"\"\"Extracts the structured content from a list of documents and stores it in JSON files.\n",
    "\n",
    "    The structured content is extracted using the indicated model_name. JSON files are saves in the indicated subfolder\n",
    "    under the \"poc2_extracts\" folder.\n",
    "\n",
    "    Args:\n",
    "        doclist: List of dictionaries with the \"document_url\" and \"code\" to extract.\n",
    "        folder: Subfolder under \"poc2_extracts\" where JSON files will be stored.\n",
    "        model_name: Name of the LLMs to user for the NER.\n",
    "        verbose: flag indicating whether to output the process progress. \n",
    "\n",
    "    Returns:\n",
    "        nothing\n",
    "    \"\"\"\n",
    "    \n",
    "    json_path = os.path.join(EXTRACTS_FOLDER, folder)\n",
    "    os.makedirs(json_path,exist_ok=True)\n",
    "\n",
    "    sleep_between_questions = 60.0 / REQUESTS_PER_MINUTE.get(model_name) if REQUESTS_PER_MINUTE.get(model_name) else 0.0\n",
    "      \n",
    "    for idx,doc in enumerate(doclist):\n",
    "\n",
    "        # A wait time might be needed to not breach the request per minute rate imposed by some LLMs.\n",
    "        if idx > 0 and (sleep_between_questions - extract_time)>0:\n",
    "            wait_s = sleep_between_questions - extract_time\n",
    "            print(\"\\n wait(s):\", wait_s)\n",
    "            time.sleep(wait_s)\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        json_file = os.path.join(json_path, doc[\"code\"].replace(\"/\",\"_\") + \".json\")\n",
    "        #print (a[\"code\"],json_file,a[\"document_url\"])\n",
    "        \n",
    "        extract({\"url\": doc[\"document_url\"],\"code\":doc[\"code\"], \"json_file\": json_file}, model_name, schema=schema, verbose=verbose)    \n",
    "\n",
    "        extract_time = time.time() - start_time\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a0463aa-5e2b-4e76-9d57-1ac53739b5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_agreement(code):\n",
    "    \"\"\"Queries the Graph to get the list of agreement codes and documents that are part or related with the given agreement.\n",
    "\n",
    "    One agreement can be related with other agreements.\n",
    "    The function will return the list of all agreements with their code and the document url.\n",
    "    The document URL is stored as the \"document_url\" property of the nodes with label \"Agreement\".\n",
    "\n",
    "    Args:\n",
    "        code: The agreement code.\n",
    "\n",
    "    Returns:\n",
    "        A list of neo4j._data.Record with the attributes \"code\" and \"document_url\"\n",
    "    \"\"\"\n",
    "    # references: https://neo4j.com/docs/python-manual/current/query-simple/#_write_to_the_database\n",
    "    driver = GraphDatabase.driver(NEO4J_URI, auth=NEO4J_AUTH) \n",
    "    \n",
    "    query=(\"MATCH (a:Agreement {code: $code})\"\n",
    "           \" RETURN a.code as code,a.document as document_url\"\n",
    "           \" UNION \"\n",
    "           \" match (a:Agreement {code: $code})-[]-(b:Agreement) \"\n",
    "           \" return b.code as code, b.document as document_url\"\n",
    "           \" order by code \"\n",
    "              )    \n",
    "    result = driver.execute_query(query,code = code)\n",
    "    \n",
    "    driver.close()\n",
    "    return result.records\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41da86e9-5b4d-4d65-afe0-09d9f7a0b6ce",
   "metadata": {},
   "source": [
    "### Components to enrich graph\n",
    "- update_graph_agreement\n",
    "- process_json_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ed1baa7-1e0d-4c07-b795-a7c4d43503cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_graph_agreement(driver, agreement):\n",
    "    \"\"\"Updates the Graph with the information extracted from the agreement.\n",
    "    \n",
    "    Using Cypher, the following transaction is performed:\n",
    "    \n",
    "        - Create any necessary new \"Person\" nodes.\n",
    "        - Create the SIGNED relationship between the \"Person\" nodes and the agreement.\n",
    "        - Add the role, organization and document properties to the SIGNED relationship.\n",
    "        - Create new Groups if the organization does not exist already.\n",
    "        - Create the REPRESENT relationship between the Person and the Organization or Group.\n",
    "        - Create the SIGNED relationship between the Organization or Group and the Agreement.\n",
    "\n",
    "    Args:\n",
    "        driver: Connection with Neo4j database.\n",
    "        agreement: Dict with the Agreement information to ingest. \n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    # Complete any missing attribute\n",
    "    if \"people\" not in agreement: agreement[\"people\"] = []\n",
    "\n",
    "    # Only consider records where the person's name is known\n",
    "    parameters= {\n",
    "        \"people\": [p for p in agreement[\"people\"] if p[\"name\"]],\n",
    "        \"code\": agreement.get(\"code\"),\n",
    "    }\n",
    "    \n",
    "    # Update the agreement connecting People, Orgs and Groups\n",
    "    if parameters[\"code\"]:\n",
    "        print(parameters[\"code\"])\n",
    "        print()\n",
    "\n",
    "        # The title and date properties of the Agreement node are NOT updated.\n",
    "        query=(\"MATCH (a:Agreement {code: $code})\"\n",
    "#              \" set d.title = $title, d.date = date($date)\"\n",
    "              \" WITH a\"\n",
    "              \" UNWIND $people AS person\" \n",
    "              \" WITH *, apoc.text.clean(replace(person.name,' i ',' ')) as pk\"\n",
    "              \" MERGE (p:Person {pk: pk}) ON CREATE set p.name=replace(person.name,' i ',' ')\"\n",
    "              \" MERGE (p)-[r:SIGNED]->(a) set r.role=person.role, r.organization=person.organization, r.document=person.document\"\n",
    "              )    \n",
    "\n",
    "        result = driver.execute_query(query,parameters_ = parameters)\n",
    "        print(\"Created {nodes_created} nodes in {time} ms.\".format(\n",
    "                nodes_created=result.summary.counters.nodes_created,\n",
    "                time=result.summary.result_available_after))\n",
    "        \n",
    "        # Create missing Organizations (Groups) and relationships\n",
    "\n",
    "        for person in parameters[\"people\"]:\n",
    "            if person.get(\"organization\"):\n",
    "                print(person)\n",
    "                print()\n",
    "                records, summary, keys = driver.execute_query(\"\"\"\n",
    "                MATCH (a:Agreement {code: $code})\n",
    "                MATCH (p:Person {pk: apoc.text.clean(replace($person.name,' i ',' '))})\n",
    "                OPTIONAL MATCH (o:Organization) WHERE apoc.text.clean(o.name)=apoc.text.clean($person.organization)\n",
    "                FOREACH (org in CASE WHEN o is null then [] else [o] end |\n",
    "                    MERGE (p)-[r:REPRESENT]->(org) ON CREATE set r.role=$person.role\n",
    "                    MERGE (org)-[s:SIGNED]->(a)\n",
    "                )\n",
    "                FOREACH (i in CASE WHEN o is null then [1] else [] end |\n",
    "                    MERGE (g:Group {pk: apoc.text.clean($person.organization)}) \n",
    "                        ON CREATE set g.name=$person.organization\n",
    "                    MERGE (p)-[rg:REPRESENT]->(g) \n",
    "                        ON CREATE set rg.role=$person.role\n",
    "                    MERGE (g)-[sg:SIGNED]->(a)\n",
    "                )\n",
    "                \"\"\", person=person, code=parameters[\"code\"])\n",
    "\n",
    "                for record in records: print(record)\n",
    "                for key in keys: print(keys)\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d5e3bf03-a842-4e08-8335-14be736178e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_json_files(folder):\n",
    "    \"\"\"Load the json files located in the specified folder into the Graph.\n",
    "\n",
    "    Load the json files by calling the update_graph_agreement procedure.\n",
    "    \n",
    "    Args:\n",
    "        folder: Folder name and file selector (e.g. \"run02_gpt4o/*.json\").\n",
    "    \"\"\"\n",
    "    \n",
    "    # Connect to Neo4j\n",
    "    driver = GraphDatabase.driver(NEO4J_URI, auth=NEO4J_AUTH) \n",
    "\n",
    "    filelist = glob.glob(os.path.join(EXTRACTS_FOLDER, folder))\n",
    "    for idx,filename in enumerate(filelist):\n",
    "        print(\"file:\", filename)\n",
    "    \n",
    "        with open(filename,'r') as fp:\n",
    "            data = json.load(fp)\n",
    "        \n",
    "        update_graph_agreement(driver, data)\n",
    "\n",
    "    driver.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402f1068-ef1d-46b8-8776-d5ae1bf6661c",
   "metadata": {},
   "source": [
    "## Process the documents for the agreement \"2022/9/0304\"\n",
    "\n",
    "To test this POC we will use the agreement \"[2022/9/0304](https://presidencia.gencat.cat/ca/ambits_d_actuacio/relacions-institucionals/registre-de-convenis-de-collaboracio-i-cooperacio/detall#2022/9/0304)\".  \n",
    "This agreement consists of 22 PDF documents published in the [Registre de convenis de col·laboració i cooperació](https://presidencia.gencat.cat/ca/ambits_d_actuacio/relacions-institucionals/registre-de-convenis-de-collaboracio-i-cooperacio/)\n",
    "\n",
    "All the agreements and the URL pointing to the corresponding PDF document are available in the graph as a result of the POC1.\n",
    "\n",
    "### Step 1: Retrieve the signees from the documents.\n",
    "\n",
    "In this step the PDF file of each agreement is parsed and its content sent to the LLM in order to extract the signees information.\n",
    "The extracted signee information together with some metadata is then stored in a JSON file for further analysis and the proper ingestion into the graph for enrichment.\n",
    "\n",
    "In order to compare the performance of different LLMs, the process is executed 4 times on all documents in scope using the following models:\n",
    "\n",
    "|Vendor| Model | Description |\n",
    "|---|---|--|\n",
    "|[OpenAI](https://openai.com)|[GPT-3.5 Turbo](https://platform.openai.com/docs/models/gpt-3-5-turbo)|The latest GPT-3.5 Turbo model with higher accuracy at responding in requested formats and a fix for a bug which caused a text encoding issue for non-English language function calls. Returns a maximum of 4,096 output tokens.|\n",
    "|[OpenAI](https://openai.com)|[GPT-4o](https://platform.openai.com/docs/models/gpt-4o)|Our most advanced, multimodal flagship model that’s cheaper and faster than GPT-4 Turbo. Currently points to gpt-4o-2024-05-13.|\n",
    "|[Anthropic](https://www.anthropic.com)|[Claude 3 Haiku](https://docs.anthropic.com/en/docs/models-overview)|Our most powerful model, delivering state-of-the-art performance on highly complex tasks and demonstrating fluency and human-like understanding|\n",
    "|[Anthropic](https://www.anthropic.com)|[Claude 3 Opus](https://docs.anthropic.com/en/docs/models-overview)|Our fastest and most compact model, designed for near-instant responsiveness and seamless AI experiences that mimic human interactions|\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efbc657d-1c85-48bc-b2ef-2f48d83f7974",
   "metadata": {},
   "source": [
    "Query the graph to get the list of agreements / documents related with \"2022/9/0304\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d2a1b2b6-6fca-4aad-adec-9a1ee4fe3960",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "doc_list = query_agreement(\"2022/9/0304\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ec48d676-5bd9-4100-84dd-1a45be946a91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022/9/0304 \n",
      " https://registredeconvenis.gencat.cat/drep_rccc/public/Convenis.do?accion=DownloadDocumentsConveni&numFila=0&numConveni=2022/P/0126\n",
      "2022/8/0004 \n",
      " https://registredeconvenis.gencat.cat/drep_rccc/public/Convenis.do?accion=DownloadDocumentsConveni&numFila=0&numConveni=2022/P/0127\n",
      "2022/8/0005 \n",
      " https://registredeconvenis.gencat.cat/drep_rccc/public/Convenis.do?accion=DownloadDocumentsConveni&numFila=0&numConveni=2022/P/0128\n",
      "2022/8/0006 \n",
      " https://registredeconvenis.gencat.cat/drep_rccc/public/Convenis.do?accion=DownloadDocumentsConveni&numFila=0&numConveni=2022/P/0129\n",
      "2022/8/0007 \n",
      " https://registredeconvenis.gencat.cat/drep_rccc/public/Convenis.do?accion=DownloadDocumentsConveni&numFila=0&numConveni=2022/P/0130\n",
      "2022/8/0008 \n",
      " https://registredeconvenis.gencat.cat/drep_rccc/public/Convenis.do?accion=DownloadDocumentsConveni&numFila=0&numConveni=2022/P/0131\n",
      "2022/8/0009 \n",
      " https://registredeconvenis.gencat.cat/drep_rccc/public/Convenis.do?accion=DownloadDocumentsConveni&numFila=0&numConveni=2022/P/0132\n",
      "2022/8/0010 \n",
      " https://registredeconvenis.gencat.cat/drep_rccc/public/Convenis.do?accion=DownloadDocumentsConveni&numFila=0&numConveni=2022/P/0133\n",
      "2022/8/0011 \n",
      " https://registredeconvenis.gencat.cat/drep_rccc/public/Convenis.do?accion=DownloadDocumentsConveni&numFila=0&numConveni=2022/P/0134\n",
      "2022/8/0012 \n",
      " https://registredeconvenis.gencat.cat/drep_rccc/public/Convenis.do?accion=DownloadDocumentsConveni&numFila=0&numConveni=2022/P/0135\n",
      "2022/8/0013 \n",
      " https://registredeconvenis.gencat.cat/drep_rccc/public/Convenis.do?accion=DownloadDocumentsConveni&numFila=0&numConveni=2022/P/0136\n",
      "2022/8/0016 \n",
      " https://registredeconvenis.gencat.cat/drep_rccc/public/Convenis.do?accion=DownloadDocumentsConveni&numFila=0&numConveni=2022/P/0243\n",
      "2022/8/0041 \n",
      " https://registredeconvenis.gencat.cat/drep_rccc/public/Convenis.do?accion=DownloadDocumentsConveni&numFila=0&numConveni=2022/P/0816\n",
      "2024/8/0047 \n",
      " https://registredeconvenis.gencat.cat/drep_rccc/public/Convenis.do?accion=DownloadDocumentsConveni&numFila=0&numConveni=2024/P/0465\n",
      "2024/8/0048 \n",
      " https://registredeconvenis.gencat.cat/drep_rccc/public/Convenis.do?accion=DownloadDocumentsConveni&numFila=0&numConveni=2024/P/0469\n",
      "2024/8/0049 \n",
      " https://registredeconvenis.gencat.cat/drep_rccc/public/Convenis.do?accion=DownloadDocumentsConveni&numFila=0&numConveni=2024/P/0472\n",
      "2024/8/0050 \n",
      " https://registredeconvenis.gencat.cat/drep_rccc/public/Convenis.do?accion=DownloadDocumentsConveni&numFila=0&numConveni=2024/P/0473\n",
      "2024/8/0051 \n",
      " https://registredeconvenis.gencat.cat/drep_rccc/public/Convenis.do?accion=DownloadDocumentsConveni&numFila=0&numConveni=2024/P/0474\n",
      "2024/8/0052 \n",
      " https://registredeconvenis.gencat.cat/drep_rccc/public/Convenis.do?accion=DownloadDocumentsConveni&numFila=0&numConveni=2024/P/0475\n",
      "2024/8/0053 \n",
      " https://registredeconvenis.gencat.cat/drep_rccc/public/Convenis.do?accion=DownloadDocumentsConveni&numFila=0&numConveni=2024/P/0477\n",
      "2024/8/0055 \n",
      " https://registredeconvenis.gencat.cat/drep_rccc/public/Convenis.do?accion=DownloadDocumentsConveni&numFila=0&numConveni=2024/P/0483\n",
      "2024/8/0056 \n",
      " https://registredeconvenis.gencat.cat/drep_rccc/public/Convenis.do?accion=DownloadDocumentsConveni&numFila=0&numConveni=2024/P/0484\n"
     ]
    }
   ],
   "source": [
    "for doc in doc_list: print(doc[\"code\"],\"\\n\", doc[\"document_url\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5772eea1-aad0-400e-b9f1-1d850734f9fb",
   "metadata": {},
   "source": [
    "#### Extract structured data from files:\n",
    "Convert the following cells from *Raw* to *Code* to perform the actual extraction.\n",
    "\n",
    "Else the JSON files with the results of each run are available in the *poc2_extracts* folder.\n",
    "\n",
    "\n",
    "> **REMEMBER**: There are some costs associated to the LLMs usage (token consumption) for running the tests. (It should be less than one USD though). Actual token usage (and cost estimate) is available in the json files for OpenAI. Token usage per call is available in LangSmith.\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "959045c5-4c84-47ef-83d0-a92399511ff7",
   "metadata": {},
   "source": [
    "# Extract files using OpenAI GPT-3.5 Turbo\n",
    "extract_documents(doc_list,\"run01_gpt35\",\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9099cfb3-3a67-40b5-9286-c47939891dc1",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# Extract files using OpenAI GPT-4o\n",
    "extract_documents(doc_list,\"run02_gpt4o\",\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "377e5650-6b36-4cea-a476-fca0c621e049",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# Extract files using Anthropic Claude 3 Haiku\n",
    "extract_documents(doc_list,\"run03_haiku\",\"claude-3-haiku\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3eb0082b-e704-430b-acdf-c6aaa4f28bd9",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# Extract files using Anthropic Claude 3 Opus\n",
    "extract_documents(doc_list,\"run04_opus\",\"claude-3-opus\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a34a68-47cd-488a-b60d-1fd051cb1d71",
   "metadata": {},
   "source": [
    "### Step 2: Ingest the JSON files into the Graph\n",
    "\n",
    "In this step we use the JSON files to enrich the Graph.<br>\n",
    "We decide to use the files produced by GPT-4o only. The rationalle behind this decision is provided in the thesis report.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8a731dd3-ee43-4135-bfa5-749ddf491e28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file: poc2_extracts/run02_gpt4o/2022_8_0041.json\n",
      "2022/8/0041\n",
      "\n",
      "Created 0 nodes in 3717 ms.\n",
      "{'name': 'Juan Pérez', 'organization': 'Universidad Nacional Autónoma de México', 'role': 'Rector', 'document': 'Nombramiento Rectoral'}\n",
      "\n",
      "{'name': 'María López', 'organization': 'Secretaría de Educación Pública', 'role': 'Secretaria', 'document': 'Nombramiento Oficial'}\n",
      "\n",
      "file: poc2_extracts/run02_gpt4o/2022_8_0016.json\n",
      "2022/8/0016\n",
      "\n",
      "Created 0 nodes in 206 ms.\n",
      "file: poc2_extracts/run02_gpt4o/2024_8_0051.json\n",
      "2024/8/0051\n",
      "\n",
      "Created 0 nodes in 5 ms.\n",
      "{'name': 'José Antonio Aguilera Núñez', 'organization': 'DEUTSCHE BANK, SAE', 'role': 'apoderat mancomunat', 'document': None}\n",
      "\n",
      "{'name': 'Jorge Mateo Saenz de Miera Alonso', 'organization': 'DEUTSCHE BANK, SAE', 'role': 'apoderat mancomunat', 'document': None}\n",
      "\n",
      "file: poc2_extracts/run02_gpt4o/2024_8_0047.json\n",
      "2024/8/0047\n",
      "\n",
      "Created 0 nodes in 159 ms.\n",
      "{'name': 'Raimon Royo Uño', 'organization': 'Arquia Bank, SA', 'role': 'Director General Adjunt', 'document': 'escriptura atorgada davant el notari , en data 28 de juliol de 2017, número del seu protocol 1.631, i inscrita al Registre Mercantil de Barcelona, en data 25 d’agost de 2017, en el volum 46.011, foli 220, full B-2.363, inscripció 308a. Aquest apoderament va ser ratificat segons escriptura atorgada davant el notari , en data 6 d’octubre de 2017 i inscrita al Registre Mercantil de Madrid, en el volum 36.871, foli 136, full M-659.820, inscripció 36a.'}\n",
      "\n",
      "file: poc2_extracts/run02_gpt4o/2024_8_0050.json\n",
      "2024/8/0050\n",
      "\n",
      "Created 0 nodes in 4 ms.\n",
      "{'name': 'Joan Cavallé Miranda', 'organization': 'CAIXA DE CRÈDIT DELS ENGINYERS-CAJA DE CRÉDITO DE LOS INGENIEROS, S.COOP. DE CRÈDIT', 'role': 'Director General', 'document': 'escriptura atorgada davant el notari, en data 20 de gener de 2006, número del seu protocol 96, i inscrita al Registre Mercantil de Barcelona, en data 7 de març de 2006, en el volum 21.606, foli 161, full B-25.121, inscripció 177a'}\n",
      "\n",
      "file: poc2_extracts/run02_gpt4o/2022_8_0006.json\n",
      "2022/8/0006\n",
      "\n",
      "Created 0 nodes in 3 ms.\n",
      "{'name': 'David Baños Baeza', 'organization': 'BANC SANTANDER, SA', 'role': 'apoderat mancomunat', 'document': 'escriptura atorgada davant el notari, en data 21 d’abril de 1998, número del seu protocol 1.316, i inscrita al Registre Mercantil de Cantabria, en data 25 de maig de 1998, en el volum 611, foli 68, full S-1.960, inscripció 402a, i segons escriptura atorgada davant el notari, en data 10 d’abril de 2013, número del seu protocol 2.287, i inscrita al Registre Mercantil de Cantabria, en el volum 1.006, foli 220, full S-1.960, inscripció 2.312a'}\n",
      "\n",
      "file: poc2_extracts/run02_gpt4o/2022_8_0010.json\n",
      "2022/8/0010\n",
      "\n",
      "Created 0 nodes in 4 ms.\n",
      "{'name': 'José Antonio Aguilera Núñez', 'organization': 'DEUTSCHE BANK, SAE', 'role': 'apoderat mancomunat', 'document': None}\n",
      "\n",
      "file: poc2_extracts/run02_gpt4o/2022_8_0011.json\n",
      "2022/8/0011\n",
      "\n",
      "Created 0 nodes in 2 ms.\n",
      "{'name': 'Ignacio Torre Sola', 'organization': 'Ibercaja Banc, SA', 'role': 'Director de Màrqueting i Estratègia Digital', 'document': 'escriptura atorgada davant el notari, en data 15 de març de 2017, número del seu protocol 589, i inscrita al Registre Mercantil de Saragossa, en data 28 de març de 2017, en el volum 4.176, foli 222, full Z-52.186, inscripció 1.225a'}\n",
      "\n",
      "file: poc2_extracts/run02_gpt4o/2022_8_0007.json\n",
      "2022/8/0007\n",
      "\n",
      "Created 0 nodes in 2 ms.\n",
      "{'name': 'Alfonso Sáez Alonso-Muñumer', 'organization': 'BANKINTER CONSUMER FINANCE EFC, SA', 'role': 'Conseller-Director General', 'document': 'escriptura atorgada davant el notari , en data 23 de juliol de 2014, número del seu protocol 2.370, i inscrita al Registre Mercantil de Madrid, en data 29 de juliol de 2014, en el volum 27.322, foli 176, full M-259.543, inscripció 82a'}\n",
      "\n",
      "file: poc2_extracts/run02_gpt4o/2024_8_0056.json\n",
      "2024/8/0056\n",
      "\n",
      "Created 0 nodes in 2 ms.\n",
      "{'name': 'Alfonso Saez Alonso-Muñumer', 'organization': 'BANKINTER CONSUMER FINANCE EFC, SA', 'role': 'Conseller-Director General', 'document': 'escriptura atorgada davant el notari Jesús Mª Ortega Fernández, en data 23 de juliol de 2014, número del seu protocol 2.370, i inscrita al Registre Mercantil de Madrid, en data 29 de juliol de 2014, en el volum 27.322, foli 176, full M-259.543, inscripció 82a'}\n",
      "\n",
      "file: poc2_extracts/run02_gpt4o/2022_9_0304.json\n",
      "2022/9/0304\n",
      "\n",
      "Created 0 nodes in 6 ms.\n",
      "{'name': 'Jaume Giró i Ribas', 'organization': 'Departament d’Economia i Hisenda', 'role': 'conseller', 'document': 'Decret 22/2021, de 26 de maig (DOGC 8418A, 26.5.2021)'}\n",
      "\n",
      "{'name': 'Violant Cervera i Gòdia', 'organization': 'Departament de Drets Socials', 'role': 'consellera', 'document': 'Decret 22/2021, de 26 de maig (DOGC 8418A, 26.5.2021)'}\n",
      "\n",
      "{'name': 'Jaume Fornt i Paradell', 'organization': 'Agència de l’Habitatge de Catalunya', 'role': 'director', 'document': 'Acord de Govern 93/2020, de 14 de juliol'}\n",
      "\n",
      "{'name': 'Jordi Òliva i Ritort', 'organization': 'Institut Català de Finances', 'role': 'conseller delegat', 'document': 'Acord de Govern GOV/175/2021, de 2 de novembre (DOGC núm. 8536, de 4 de novembre de 2021)'}\n",
      "\n",
      "{'name': 'Josep Lores i García', 'organization': 'Avalis de Catalunya, SGR', 'role': 'conseller delegat', 'document': 'escriptura pública atorgada davant el notari de Barcelona, en data 10 de juny de 2021, amb número de protocol 2'}\n",
      "\n",
      "file: poc2_extracts/run02_gpt4o/2022_8_0008.json\n",
      "2022/8/0008\n",
      "\n",
      "Created 0 nodes in 2 ms.\n",
      "{'name': 'José Raúl Pérez González de Uriarte', 'organization': 'BANC BILBAO VIZCAYA ARGENTARIA, SA', 'role': 'apoderat', 'document': 'escriptura atorgada davant el notari, en data 3 de desembre de 2020, número del seu protocol 2216, i inscrita al Registre Mercantil de Bizkaia, en data 9 de desembre de 2020, en el volum 5.928, foli 153, full BI-17-A, inscripció 4.164a'}\n",
      "\n",
      "file: poc2_extracts/run02_gpt4o/2024_8_0055.json\n",
      "2024/8/0055\n",
      "\n",
      "Created 0 nodes in 2 ms.\n",
      "{'name': 'Maria Alsina Call', 'organization': 'CaixaBank, SA', 'role': 'apoderada', 'document': 'escriptura atorgada davant el notari , en data 16 d’octubre de 2017, número del seu protocol 2.722, i inscrita al Registre Mercantil de València, en data 6 de novembre de 2017, en el volum 10.370, foli1, full V-178.351, inscripció 3a'}\n",
      "\n",
      "file: poc2_extracts/run02_gpt4o/2022_8_0012.json\n",
      "2022/8/0012\n",
      "\n",
      "Created 0 nodes in 4 ms.\n",
      "{'name': 'Roberto Colomer Blasco', 'organization': 'Unió de Crèdits Immobiliaris, SA, Establiment Financer de Crèdit', 'role': 'Director General', 'document': None}\n",
      "\n",
      "file: poc2_extracts/run02_gpt4o/2022_8_0004.json\n",
      "2022/8/0004\n",
      "\n",
      "Created 0 nodes in 3 ms.\n",
      "{'name': 'Raimon Royo Uño', 'organization': 'Arquia Bank, SA', 'role': 'Director General Adjunt', 'document': 'escriptura atorgada davant el notari , en data 28 de juliol de 2017, número del seu protocol 1.631, i inscrita al Registre Mercantil de Barcelona, en data 25 d’agost de 2017, en el volum 46.011, foli 220, full B-2.363, inscripció 308a. Aquest apoderament va ser ratificat segons escriptura atorgada davant el notari , en data 6 d’octubre de 2017 i inscrita al Registre Mercantil de Madrid, en el volum 36.871, foli 136, full M-659.820, inscripció 36a.'}\n",
      "\n",
      "file: poc2_extracts/run02_gpt4o/2022_8_0005.json\n",
      "2022/8/0005\n",
      "\n",
      "Created 0 nodes in 41 ms.\n",
      "{'name': 'David Massana Gracia', 'organization': 'Banc de Sabadell, SA', 'role': 'apoderat', 'document': 'escriptura atorgada davant el notari, en data 25 de juliol de 2019, número del seu protocol 2.774, i inscrita al Registre Mercantil d’Alacant, en data 16 d’agost de 2019, en el volum 4.070, foli 85, full A-156.980, inscripció 164a'}\n",
      "\n",
      "file: poc2_extracts/run02_gpt4o/2022_8_0013.json\n",
      "2022/8/0013\n",
      "\n",
      "Created 0 nodes in 2 ms.\n",
      "file: poc2_extracts/run02_gpt4o/2022_8_0009.json\n",
      "2022/8/0009\n",
      "\n",
      "Created 0 nodes in 1 ms.\n",
      "{'name': 'Joan Cavallé Miranda', 'organization': 'CAIXA DE CRÈDIT DELS ENGINYERS-CAJA DE CRÉDITO DE LOS INGENIEROS, S.COOP. DE CRÈDIT', 'role': 'Director General', 'document': None}\n",
      "\n",
      "file: poc2_extracts/run02_gpt4o/2024_8_0049.json\n",
      "2024/8/0049\n",
      "\n",
      "Created 0 nodes in 2 ms.\n",
      "{'name': 'José Raúl Pérez González de Uriarte', 'organization': 'Banc Bilbao Vizcaya Argentaria, SA', 'role': 'apoderat', 'document': 'escriptura atorgada davant el notari en data 3 de desembre de 2020, número del seu protocol 2216, i inscrita al Registre Mercantil de Bizkaia, en data 9 de desembre de 2020, en el volum 5.928, foli 153, full BI-17-A, inscripció 4.164a'}\n",
      "\n",
      "file: poc2_extracts/run02_gpt4o/2024_8_0053.json\n",
      "2024/8/0053\n",
      "\n",
      "Created 0 nodes in 2 ms.\n",
      "{'name': 'Philippe Jacques Laporte', 'organization': 'Unió de Crèdits Immobiliaris, SA, Establiment Financer de Crèdit', 'role': 'Director d’operacions (COO)', 'document': 'escriptura atorgada davant el notari en data 19 de juny de 1997, número del seu protocol 2.859'}\n",
      "\n",
      "file: poc2_extracts/run02_gpt4o/2024_8_0052.json\n",
      "2024/8/0052\n",
      "\n",
      "Created 0 nodes in 2 ms.\n",
      "{'name': 'Ignacio Torre Sola', 'organization': 'Ibercaja Banc, SA', 'role': 'Director de Màrqueting i Estratègia Digital', 'document': 'escriptura atorgada davant el notari, en data 15 de març de 2017, número del seu protocol 589, i inscrita al Registre Mercantil de Saragossa, en data 28 de març de 2017, en el volum 4.176, foli 222, full Z-52.186, inscripció 1.225a'}\n",
      "\n",
      "file: poc2_extracts/run02_gpt4o/2024_8_0048.json\n",
      "2024/8/0048\n",
      "\n",
      "Created 0 nodes in 17 ms.\n",
      "{'name': 'David Massana Gracia', 'organization': 'Banc de Sabadell, SA', 'role': 'apoderat', 'document': 'escriptura atorgada davant el notari , en data 25 de juliol de 2019, número del seu protocol 2.774, i inscrita al Registre Mercantil d’Alacant, en data 16 d’agost de 2019, en el volum 4.070, foli 85, full A-156.980, inscripció 164a'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "process_json_files(\"run02_gpt4o/*.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51780518-490b-4b5c-b5e6-c2afb49bc736",
   "metadata": {},
   "source": [
    "**POC 2 Notebook ends here.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
